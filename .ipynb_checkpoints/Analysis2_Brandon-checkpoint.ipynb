{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7, 4.5)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#use regressor for numerical values, and classifier for string labels\n",
    "\n",
    "# use RF on every var as y, sum up importance across rows\n",
    "# for city, province and region, make them mutually exclusive when fitting\n",
    "# column is the Y value used\n",
    "\n",
    "data1 = pd.read_csv(\"OutliersRemoved2.csv\")\n",
    "data1 = data1.drop(data1.columns[[0,3,5,6]],axis = 1)\n",
    "# remove chinese name, province key,region key, year\n",
    "features = data1.describe()\n",
    "locations = ['City/province name (EN)','Province','Region']\n",
    "\n",
    "# imputation by subbing with mean on data\n",
    "for i in list(data1):\n",
    "    # cannot impute non-numerical data\n",
    "    if i not in locations:\n",
    "        data1[i] = data1[i].fillna(features[i].loc[\"mean\"])\n",
    "    \n",
    "# shuffle \n",
    "data1 = shuffle(data1, random_state = 0)\n",
    "\n",
    "# separate loop for the city, province and region\n",
    "importances = pd.DataFrame(data =0,index = data1.columns,columns = data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a whole night to run; run it on a separate notebook to prevent computer crashing (memory)\n",
    "rf2 = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "# drop the non-numericals\n",
    "X3 = data1.drop(locations,axis=1)\n",
    "\n",
    "\n",
    "for y_val in list(X3):\n",
    "    Y3 = X3[y_val]\n",
    "    X3 = X3.drop(y_val, axis =1)\n",
    "    X3_train, X3_test, Y3_train, Y3_test = train_test_split(X3, Y3, test_size=0.20, random_state = 0)\n",
    "    rf2.fit(X3_train, Y3_train)\n",
    "    run = rf2.feature_importances_ \n",
    "\n",
    "    d = dict(zip(X3.columns,run))\n",
    "    for x in X3.columns:\n",
    "        importances.loc[x,y_val] = d[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unlooped for the three non-numerical to improve runtime\n",
    "\n",
    "#predict city\n",
    "X4 = data1.drop(['Province','Region'],axis=1)\n",
    "Y4 = X4[\"City/province name (EN)\"]\n",
    "X4 = X4.drop(\"City/province name (EN)\", axis =1)\n",
    "X4_train, X4_test, Y4_train, Y4_test = train_test_split(X4, Y4, test_size=0.20, random_state = 0)\n",
    "rf2.fit(X4_train, Y4_train)\n",
    "run = rf2.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paste information into importances df\n",
    "d = dict(zip(X4.columns,run))\n",
    "for x in X4.columns:\n",
    "    if (x != \"City/province name (EN)\"):\n",
    "        importances.loc[x,\"City/province name (EN)\"] = d[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict provinces\n",
    "X4 = data1.drop(['City/province name (EN)','Region'],axis=1)\n",
    "Y4 = X4[\"Province\"]\n",
    "X4 = X4.drop(\"Province\", axis = 1)\n",
    "X4_train, X4_test, Y4_train, Y4_test = train_test_split(X4, Y4, test_size=0.20, random_state = 0)\n",
    "rf2.fit(X4_train, Y4_train)\n",
    "run = rf2.feature_importances_ \n",
    "\n",
    "imp = pd.DataFrame( \n",
    "        run , \n",
    "        columns = [ \"Province\" ] , \n",
    "        index = X4.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paste information into importances df\n",
    "d = dict(zip(X4.columns,run))\n",
    "for x in X4.columns:\n",
    "    if (x !=  \"Province\" ):\n",
    "        importances.loc[x, \"Province\" ] = d[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict region\n",
    "X4 = data1.drop(['City/province name (EN)','Province'],axis=1)\n",
    "Y4 = X4[\"Region\"]\n",
    "X4 = X4.drop(\"Region\", axis =1)\n",
    "X4_train, X4_test, Y4_train, Y4_test = train_test_split(X4, Y4, test_size=0.20, random_state = 0)\n",
    "rf2.fit(X4_train, Y4_train)\n",
    "run = rf2.feature_importances_ \n",
    "\n",
    "imp = pd.DataFrame( \n",
    "        run , \n",
    "        columns = [ \"Region\" ] , \n",
    "        index = X4.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paste information into importances df\n",
    "d = dict(zip(X4.columns,run))\n",
    "for x in X4.columns:\n",
    "    if (x != \"Region\"):\n",
    "        importances.loc[x,\"Region\"] = d[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum across rows and place into imp_sum\n",
    "imp_sum = pd.DataFrame(data = importances.sum(axis=1),index = data1.columns,columns = [\"Importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the sums to show which features are the most important for variation\n",
    "# graph the 3 classifiers and the top 10 regressors separately\n",
    "\n",
    "# 3 classifiers\n",
    "classifiers = imp_sum.drop(imp_sum.index[3::])\n",
    "classifiers = classifiers.sort_values( [ 'Importance' ] , ascending = True )\n",
    "classifiers.plot( kind = 'barh' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 regressors\n",
    "regressors = imp_sum.drop(imp_sum.index[0:3])\n",
    "regressors = regressors.sort_values( [ 'Importance' ] , ascending = True )\n",
    "regressors[:10].plot( kind = 'barh' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"use feature scaling on train/test for logreg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"using regularization within logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"try clustering for visualzation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
